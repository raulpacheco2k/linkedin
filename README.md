Este projeto realiza a raspagem de dados de vagas de emprego do LinkedIn para identificar as tecnologias mais
requisitadas no mercado de trabalho. Atualmente, apenas a descri√ß√£o das vagas √© raspada. Futuramente, ser√£o
implementadas funcionalidades para capturar mais dados, como nome da empresa, tamanho da empresa, n√∫mero de aplica√ß√µes
na vaga, modalidade de trabalho, entre outros.

# Instala√ß√£o e configura√ß√£o

Voc√™ deve ter instalado previamente **Python 3.12** e **Pip 23.2**, nessas vers√µes ou posteriores.

## Instala√ß√£o

```bash
pip install -r requirements.txt
```

## Configura√ß√£o

### 1.¬∞ Passo: Adicionando suporte ao Selenium 4

Este projeto utiliza Scrapy, Selenium e uma biblioteca chamada scrapy-selenium, que infelizmente n√£o √© mais mantida e
suporta apenas Selenium 3. Queremos rodar com Selenium 4, ent√£o precisamos fazer algumas modifica√ß√µes.

Para isso, execute o comando abaixo para encontrar a localiza√ß√£o da instala√ß√£o do
scrapy-selenium: ```pip show scrapy-selenium | grep Location```.

Acesse a pasta retornada e substitua o arquivo middlewares.py da biblioteca pelo arquivo middlewares.py presente na raiz
deste projeto. Isso adicionar√° suporte ao Selenium 4.

### 2.¬∞ Passo: Preencher os dados de acesso ao LinkedIn

```bash
cp config_template.py config.py
```

* Preenche EMAIL com seu e-mail do LinkedIn
* Preenche SENHA com sua senha do LinkedIn
* Preencha URL com o url das vagas do LinkedIn que voc√™ deseja raspar, elas devem come√ßar
  com `https://www.linkedin.com/jobs/search/`

### 3.¬∞ Passo: Definindo o navegador

Este projeto utiliza Selenium, que precisa do driver do seu navegador para funcionar. Se optar por usar
outro navegador que n√£o seja o Chrome, acesse o arquivo `linkedin/linkedin/settings.py` e mude o valor da vari√°vel
SELENIUM_DRIVER_NAME para o nome do driver do seu navegador.

üéâ Ap√≥s isso, o script estar√° pronto para ser executado!

# Executando o script

## 1.¬∞ Passo: raspando os dados

No arquivo `linkedin/linkedin/spiders/jobs.py` existe um `sleep(60)`. Esse sleep √© necess√°rio porque o LinkedIn pode
solicitar a resolu√ß√£o de um captcha ou um c√≥digo enviado ao e-mail. Ap√≥s o Selenium fazer o login, ele ficar√° parado por
60 segundos para que isso seja resolvido. Isso normalmente ocorre apenas nos primeiros acessos. Ap√≥s isso, esse sleep
pode ser removido.

```bash
cd linkedin
scrapy crawl jobs -o jobs_example.json
```

## 2.¬∞ Passo: analisando os dados

1. No arquivo main.py, h√° v√°rias tecnologias listadas em `technologies`. Apenas as tecnologias listadas aqui aparecer√£o
   na an√°lise. Caso a tecnologia que voc√™ deseja analisar n√£o esteja listada, adicione-a e envie um PR.
2. Atualmente, a exibi√ß√£o √© feita no terminal. Sinta-se √† vontade para editar isso. Futuramente, os dados ser√£o
   analisados utilizando Streamlit.
